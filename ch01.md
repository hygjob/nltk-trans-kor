원문 http://www.nltk.org/book/



머리말**

이것은 자연어 처리에 관한 책입니다. "자연어"란 인간이 일상적으로 의사 소통하는 데 사용되는 언어를 의미합니다. 영어, 한국어, 힌디어 또는 포르투갈어와 같은 언어입니다. 프로그래밍 언어 및 수학 표기법과 같은 인공 언어와 달리 자연 언어는 세대를 거치면서 진화하고 명시적인 규칙으로 고정하기가 어렵습니다. 우리는 자연어 처리 (즉, NLP)를 다양한 의미의 컴퓨터 언어를 다루는 넓은 의미에서 취할 것입니다. 경우에 따라선, 다른 작문 스타일을 비교하기 위해 단어 빈도를 세는 것만 큼 간단 할 수 있습니다. 때론 NLP는 적어도 사람들에게 유용한 반응을 줄 수있는 정도까지의 인간의 발언에  "이해"를 포함하기도 합니다. 


NLP를 기반으로 한 기술이 점점 더 널리 보급되고 있습니다. 예를 들어, 휴대 전화 및 핸드 헬드 컴퓨터는 예측 텍스트 및 필기 인식을 지원합니다. 웹 검색 엔진은 구조화되지 않은 텍스트에 숨겨진 정보에 대한 액세스를 제공합니다. 기계 번역을 통해 우리는 중국어로 된 텍스트를 검색하고 스페인어로 읽을 수 있습니다. 텍스트 분석을 통해 트윗과 블로그의 정서를 감지 할 수 있습니다. 더 자연스러운 인간 - 기계 인터페이스와 저장된 정보에 대한보다 정교한 액세스를 제공함으로써 언어 처리는 정보 사회에서 핵심적인 역할을 수행하게되었습니다.

이 책은 NLP 분야에 대한 접근을 용이하게 합니다. 개별 학습이나 자연 언어 처리 또는 전산 언어학 과정의 교과서 또는 인공 지능, 텍스트 마이닝 또는 코퍼스 언어학 과정의 보충 교재로 사용할 수 있습니다. 이 책은 수많은 실용적인 예제와 단계별 실습을 포함하였기에 굉장히 실용적입니다.

이 책은 Python 프로그래밍 언어와 NLTK (Natural Language Toolkit)라는 오픈 소스 라이브러리를 기반으로합니다. NLTK는 http://nltk.org/에서 무료로 다운로드 할 수있는 광범위한 소프트웨어, 데이터 및 문서를 포함합니다. Windows, Macintosh 및 Unix 플랫폼에 대한 배포판이 제공됩니다. 파이썬과 NLTK를 다운로드하고 예제와 연습을 시도해보십시오.

**독자**

NLP는 과학적, 경제적, 사회적, 문화적 이유로 중요합니다. NLP는 이론과 방법이 다양한 새로운 언어 기술에 배치되면서 급속한 성장을 경험하고 있습니다. 이러한 이유로 많은 사람들이 NLP에 대한 실무 지식을 갖는 것이 중요합니다. 업계 내에서 이것은 인간 - 컴퓨터 상호 작용, 비즈니스 정보 분석 및 웹 소프트웨어 개발 분야의 사람들을 포함합니다. 학계 내에서는 인문학 컴퓨팅 및 코퍼스 언어학에서부터 컴퓨터 과학 및 인공 지능에 이르는 사람들이 포함됩니다. (학계의 많은 사람들에게 NLP는 "Computational Linguistics"라는 이름으로 알려져 있습니다.)

이 책은 이전 프로그래밍 경험에 관계없이 텍스트를 분석하는 프로그램을 작성하는 방법을 배우려는 다양한 사람들을 대상으로합니다.

| New to programming?:         |                                                              |
| ---------------------------- | ------------------------------------------------------------ |
|                              | 이 책의 초기 장은 새로운 개념을 다루고 새로운 컴퓨팅 기술을 개발하는 것을 두려워하지 않는 한 프로그래밍에 대한 사전 지식이없는 독자에게 적합합니다. 이 책에는 수백 가지의 단계별 연습과 함께 복사하고 직접 시도 할 수있는 예제가 가득합니다. 파이썬에 대한 좀 더 일반적인 소개가 필요한 경우 http://docs.python.org/에있는 파이썬 리소스 목록을 참조하십시오. |
| New to Python?:              | 숙련 된 프로그래머는 자연 언어 처리에 익숙해지기 위해이 책을 사용하여 충분한 Python을 빨리 배울 수 있습니다. 관련된 모든 Python 기능을 신중하게 설명하고 예시하며,이 애플리케이션 영역에 대한 Python의 적합성을 금방 알게 될 것입니다. 언어 색인은 책에서 관련 토론을 찾을 수 있도록 도와줍니다. |
| Already dreaming in Python?: |                                                              |
|                              | 파이썬 예제를 건너 뛰고 1장에서 시작되는 재미있는 언어 분석 자료를 살펴보십시오. 곧이 매혹적인 영역에 기술을 적용 할 것입니다. |

**강조사항**


이 책은 NLP에 대한 실용적인 소개입니다. 예제를 통해 배우고, 실제 프로그램을 작성하고, 구현을 통해 아이디어를 테스트 할 수있는 가치를 파악합니다. 이미 배운 적이 없다면이 책은 프로그래밍을 가르쳐 줄 것입니다. 다른 프로그래밍 서적과 달리 NLP에서 제공하는 광범위한 일러스트레이션과 연습을 제공합니다. 우리가 취한 접근 방식은 또한 이론적 토대를 다루고 언어 및 계산적인 측면에서도 충실하였습니다. 우리는 이론과 응용 사이의 균형을 깨닫고 실용 주의적인 노선에서 노력했습니다. 마지막으로, 즐겁고 재미 있고 때로는 기발한 많은 응용 프로그램과 예제를 포함 시키려 노력했습니다.

이 책은 참고 자료가 아닙니다. 파이썬과 NLP를 다루고 있으며 튜토리얼 형식으로 구성하였습니다.. 참고 자료는 http://python.org/ 및 http://nltk.org/에서 제공되는 많은  리소스를 참조하십시오.

이 책은 전문 컴퓨터 과학 책은 아닙니다. 내용은 입문에서 중급까지 다양하며 Python과 Natural Language Toolkit을 사용하여 텍스트를 분석하는 방법을 배우려는 독자를 대상으로합니다. NLTK에서 구현 된 고급 알고리즘을 배우려면 http://nltk.org/에서 링크 된 Python 코드를 검토하고 이 책에 인용 된 다른 자료를 참조하십시오.

**배우게 될 것**


여기에 제시된 자료를 살펴보면 다음과 같은 내용을 배우게됩니다.

얼마나 간단한 프로그램이 언어 데이터를 조작하고 분석하는지, 그리고이 프로그램을 작성하는 방법
NLP와 언어학의 핵심 개념을 사용하여 언어를 기술하고 분석하는 방법
NLP에서 데이터 구조와 알고리즘을 사용하는 방법
언어 데이터가 표준 형식으로 저장되는 방법과 데이터를 사용하여 NLP 기술의 성능을 평가하는 방법
배경과 NLP에 관심이있는 동기에 따라 III.1에서 설명한대로이 책에서 여러 가지 기술과 지식을 습득하게됩니다.

표 III.1 :

독자의 목표와 배경에 따라이 책을 읽음으로써 얻을 수있는 기술과 지식

| Goals               | Background in arts and humanities                            | Background in science and engineering                        |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Language analysis   | 코포라 처리, 언어 모델 탐색 및 경험적 주장 테스트.           | 자연 언어를 분석하기 위해 데이터 모델링, 데이터 마이닝 및 지식 발견 기술을 사용합니다. |
| Language technology | 기술 응용 프로그램으로 언어 작업을 수행 할 수있는 견고한 시스템 구축 | 강력한 언어 처리 소프트웨어에서 언어 알고리즘 및 데이터 구조 사용 |

**구성**


초기 챕터는 작은 파이썬 프로그램 (1-3 장)을 사용하여 흥미로운 텍스트 본문을 탐색하는 방법을 보여주는 언어 처리에 대한 실용적인 소개부터 개념적 어려움의 순서로 구성되어 있습니다. 그 다음에는 이전 장 전반에 흩어져있는 프로그래밍 주제를 통합하는 구조화 프로그래밍 (4 장) 장이 뒤 따릅니다. 그 다음에 페이스가 결정되고 언어 처리의 기본 주제 인 태깅, 분류 및 정보 추출 (5 ~ 7 장)을 다루는 일련의 장으로 이동합니다. 다음 세 장에서는 문장을 구문 분석하고 구문 구조를 인식하며 의미를 표현하는 방법을 살펴 본다 (8-10 장). 마지막 장은 언어 데이터와 효과적인 관리 방법에 대해 다룹니다 (11 장). 이 책은 필드의 과거와 미래를 간략하게 논의하는 후일 워드로 마무리됩니다.

각 장에서 다양한 스타일의 프리젠 테이션으로 전환합니다. 한 가지 스타일에서 자연어가 운전자입니다. 우리는 언어를 분석하고, 언어 개념을 탐구하며, 프로그래밍 예제를 사용하여 토론을 지원합니다. 우리는 체계적으로 도입되지 않은 Python 구문을 종종 사용하기 때문에, 어떻게 작동하는지 그리고 왜 작동하는지에 대한 세부 사항을 파고 들기 전에 그 목적을 알 수 있습니다. 이는 외국어로 관용적 인 표현을 배우는 것과 같습니다. 질문 형성의 복잡함을 처음에 배우지 않고 멋진 과자를 살 수 있습니다. 다른 스타일의 프리젠 테이션에서는 프로그래밍 언어가 드라이버가 될 것입니다. 우리는 프로그램을 분석하고, 알고리즘을 탐색하며, 언어 적 예제가 지원 역할을 수행 할 것입니다.

각 장은 일련의 단계별 연습으로 끝나며 자료를 통합하는 데 유용합니다. 연습은 다음과 같은 계획에 따라 등급이 매겨집니다. supplied 제공된 코드 샘플 또는 기타 간단한 활동에 대한 사소한 수정을 포함하는 쉬운 연습을위한 것입니다. careful 신중한 분석과 설계가 요구되는보다 심층적 인 자료의 측면을 탐구하는 중급 연습을위한 것입니다. ★ 어렵고 개방적인 작업을위한 것으로, 재료에 대한 이해를 어렵게하고 독창적으로 생각하도록 강요합니다 (프로그래밍을 처음 접하는 독자는이를 건너 뜁니다).

각 장에는 http://nltk.org/에서 더 많은 독서 섹션과 온라인 "추가 정보"섹션이 있으며 고급 자료와 온라인 리소스에 대한 정보가 있습니다. 모든 코드 예제의 온라인 버전도 제공됩니다.



**왜 파이썬인가?**


Python은 간단하지만 강력한 프로그래밍 언어로서 언어 데이터 처리 기능이 뛰어납니다. Python은 http://python.org/에서 무료로 다운로드 할 수 있습니다. 설치 프로그램은 모든 플랫폼에서 사용할 수 있습니다.

다음은 file.txt를 처리하고 ing에서 끝나는 모든 단어를 인쇄하는 5 행 Python 프로그램입니다.

```python
>>> for line in open("file.txt"):
...     for word in line.split():
...         if word.endswith('ing'):
...             print(word)
```



이 프로그램은 Python의 주요 기능 중 일부를 보여줍니다. 첫째, 공백은 코드 줄을 중첩하는 데 사용되므로,로 시작하는 줄은 for로 시작하는 이전 줄의 범위에 속합니다. 이렇게하면 각 단어에 대해 ing 테스트가 수행됩니다. 둘째, 파이썬은 객체 지향적입니다. 각 변수는 특정 속성 및 메소드가 정의 된 엔티티입니다. 예를 들어, 변수 행의 값은 일련의 문자 이상입니다. 이것은 라인을 단어로 나눌 때 사용할 수있는 split ()이라는 "메소드"(또는 연산)를 가진 문자열 객체입니다. 객체에 메소드를 적용하려면 객체 이름 뒤에 마침표를 붙여 메소드 이름 (예 : line.split ())을 씁니다. 셋째, 메소드는 괄호 안에 인수가 표시됩니다. 예를 들어,이 예에서 word.endswith ( 'ing')에는 'ing'이라는 인수가 있는데 이는 ing으로 끝나는 단어와 다른 단어가 필요 없다는 것을 나타냅니다. 마지막으로 - 가장 중요한 것은 - 파이썬은 읽기 쉽기 때문에 이전에 프로그램을 작성한 적은 없더라도 프로그램이 무엇을하는지 쉽게 추측 할 수 있습니다.

파이썬은 학습 곡선이 얕고, 구문과 의미가 투명하며, 문자열 처리 기능이 뛰어 나기 때문에 Python을 선택했습니다. 인터프리터 언어로서, 파이썬은 쌍방향 탐색을 용이하게합니다. 객체 지향 언어 인 Python은 데이터와 메소드를 캡슐화하고 쉽게 다시 사용할 수 있도록 허용합니다. 동적 인 언어로서, Python은 속성을 즉시 객체에 추가 할 수있게 해주 며, 변수를 동적으로 입력 할 수 있으므로 신속한 개발이 가능합니다. Python은 그래픽 프로그래밍, 수치 처리 및 웹 연결을위한 구성 요소를 포함하여 광범위한 표준 라이브러리와 함께 제공됩니다.

파이썬은 전 세계의 산업, 과학 연구 및 교육에 많이 사용됩니다. 파이썬은 종종 소프트웨어의 생산성, 품질 및 유지 보수를 용이하게하는 방법으로 높이 평가됩니다. Python 성공 사례 모음은 http://python.org/about/success/에 게시되어 있습니다.

NLTK는 Python으로 NLP 프로그램을 작성하는 데 사용할 수있는 인프라를 정의합니다. 자연 언어 처리와 관련된 데이터를 표현하기위한 기본 클래스를 제공합니다. 품사 (part-of-speech) 태깅, 구문 구문 분석 및 텍스트 분류와 같은 작업을 수행하기위한 표준 인터페이스; 복잡한 문제를 해결하기 위해 결합 될 수있는 각 작업에 대한 표준 구현 등이 포함됩니다.

NLTK는 광범위한 문서와 함께 제공됩니다. 이 책 외에도 http://nltk.org/에있는 웹 사이트는 툴킷의 모든 모듈, 클래스 및 기능, 매개 변수 지정 및 사용 예를 제공하는 API 설명서를 제공합니다.



**파이썬 3 및 NLTK 3**


이 버전의 책은 Python 3과 NLTK 3을 지원하도록 업데이트되었습니다. Python 3에는 몇 가지 중요한 변경 사항이 포함되어 있습니다.

- print 문은 이제 괄호가 필요한 함수입니다.
- 많은 함수가 이제는 목록 대신 반복자를 반환합니다 (메모리 사용량을 절약하기 위해).
- 정수 나누기 부동 소수점 숫자를 반환합니다.
- 모든 텍스트가 이제 유니 코드입니다.
- 문자열은 format 메서드를 사용하여 형식이 지정됩니다.
- 변경 사항에 대한 자세한 내용은 https://docs.python.org/dev/whatsnew/3.0.html을 참조하십시오. 

파이썬 2 코드를 파이썬 3으로 변환 할 수있는 2to3.py라는 유틸리티가 있습니다. 자세한 내용은 https://docs.python.org/2/library/2to3.html을 참조하십시오.

NLTK는 또한 보편적 인 변화를 포함합니다 :

- fromstring () 메서드를 사용하여 많은 유형이 문자열에서 초기화됩니다.
- 많은 함수가 이제 목록 대신 반복자를 반환합니다.
- ContextFreeGrammar는 이제 CFG로, WeightedGrammar는 이제 PCFG라고합니다.
- 이제 batch_tokenize ()를 tokenize_sents ()라고합니다. 배치 태거, 파서 및 분류 자에 해당하는 변경 사항이 있습니다.
- 일부 구현은 외부 패키지를 위해 제거되었거나 적절하게 유지 관리 할 수 없었기 때문에 제거되었습니다.

변경 사항에 대한 자세한 내용은 https://github.com/nltk/nltk/wiki/Porting-your-code-to-NLTK-3.0을 참조하십시오.



**소프트웨어 요구사항**



이 책을 최대한 활용하려면 몇 가지 무료 소프트웨어 패키지를 설치해야합니다. 현재 다운로드 포인터 및 지침은 http://nltk.org/에서 제공됩니다.

| Python:             | The material presented in this book assumes that you are using Python version 3.2 or later. (Note that NLTK 3.0 also works with Python 2.6 and 2.7.) |
| ------------------- | ------------------------------------------------------------ |
| NLTK:               | The code examples in this book use NLTK version 3.0. Subsequent releases of NLTK will be backward-compatible with NLTK 3.0. |
| NLTK-Data:          | This contains the linguistic corpora that are analyzed and processed in the book. |
| NumPy:              | (recommended) This is a scientific computing library with support for multidimensional arrays and linear algebra, required for certain probability, tagging, clustering, and classification tasks. |
| Matplotlib:         | (recommended) This is a 2D plotting library for data visualization, and is used in some of the book's code samples that produce line graphs and bar charts. |
| Stanford NLP Tools: |                                                              |
|                     | (recommended) NLTK includes interfaces to the Stanford NLP Tools which are useful for large scale language processing (see `http://nlp.stanford.edu/software/`). |
| NetworkX:           | (optional) This is a library for storing and manipulating network structures consisting of nodes and edges. For visualizing semantic networks, also install the *Graphviz* library. |
| Prover9:            | (optional) This is an automated theorem prover for first-order and equational logic, used to support inference in language processing. |



**자연 언어 도구 키트 (NLTK)**
NLTK는 원래 펜실베이니아 대학의 컴퓨터 및 정보 과학과의 컴퓨터 언어학 과정의 일환으로 2001 년에 만들어졌습니다. 그 이후로 수십 명의 기여자의 도움을 받아 개발 및 확장되었습니다. 현재 수십 개의 대학에서 수강하고 있으며 많은 연구 프로젝트의 기초가됩니다. 가장 중요한 NLTK 모듈 목록은 VIII.1을 참조하십시오.

표 VIII.1 :

기능의 예가있는 언어 처리 태스크 및 해당 NLTK 모듈

| Language processing task   | NLTK modules           | Functionality                                                |
| -------------------------- | ---------------------- | ------------------------------------------------------------ |
| Accessing corpora          | corpus                 | standardized interfaces to corpora and lexicons              |
| String processing          | tokenize, stem         | tokenizers, sentence tokenizers, stemmers                    |
| Collocation discovery      | collocations           | t-test, chi-squared, point-wise mutual information           |
| Part-of-speech tagging     | tag                    | n-gram, backoff, Brill, HMM, TnT                             |
| Machine learning           | classify, cluster, tbl | decision tree, maximum entropy, naive Bayes, EM, k-means     |
| Chunking                   | chunk                  | regular expression, n-gram, named-entity                     |
| Parsing                    | parse, ccg             | chart, feature-based, unification, probabilistic, dependency |
| Semantic interpretation    | sem, inference         | lambda calculus, first-order logic, model checking           |
| Evaluation metrics         | metrics                | precision, recall, agreement coefficients                    |
| Probability and estimation | probability            | frequency distributions, smoothed probability distributions  |
| Applications               | app, chat              | graphical concordancer, parsers, WordNet browser, chatbots   |
| Linguistic fieldwork       | toolbox                | manipulate data in SIL Toolbox format                        |



NLTK는 다음 네 가지 기본 목표를 염두에두고 설계되었습니다.

| Simplicity:    | To provide an intuitive framework along with substantial building blocks, giving users a practical knowledge of NLP without getting bogged down in the tedious house-keeping usually associated with processing annotated language data |
| -------------- | ------------------------------------------------------------ |
| Consistency:   | To provide a uniform framework with consistent interfaces and data structures, and easily-guessable method names |
| Extensibility: | To provide a structure into which new software modules can be easily accommodated, including alternative implementations and competing approaches to the same task |
| Modularity:    | To provide components that can be used independently without needing to understand the rest of the toolkit |

이러한 목표와 대조적으로, 우리가 의도적으로 피한 3 가지의 비 필수적인 잠재 성이 있습니다. 첫째, 툴킷은 다양한 기능을 제공하지만 백과 사전이 아닙니다. 그것은 시스템이 아니라 툴킷이며 NLP 분야에서 계속 진화 할 것입니다. 둘째, 툴킷은 의미있는 작업을 지원할만큼 효율적이지만 런타임 성능을 위해 최적화 된 것은 아닙니다. 이러한 최적화에는 종종 더 복잡한 알고리즘 또는 C 또는 C ++와 같은 저수준 프로그래밍 언어에서의 구현이 포함됩니다. 이렇게하면 소프트웨어를 쉽게 읽을 수없고 설치하기가 어려워집니다. 셋째, 독창적이고 아직 읽을 수없는 프로그램보다 명확한 구현이 바람직하다고 생각하기 때문에 영리한 프로그래밍 기법을 피하려고 노력했습니다.



**강의자가 알아둘 사항**

자연어 처리는 종종 고급 학부 수준 또는 대학원 수준의 단일 학기 과정의 범위 내에서 진행됩니다. 많은 강사들은 짧은 시간 내에 주제의 이론적 측면과 실무 측면을 모두 다루는 것이 어렵다는 것을 발견했습니다. 일부 코스는 이론에 초점을 맞추어 실습을 배제하여 학생들이 언어를 자동으로 처리하는 프로그램 작성을 통해 배우는 도전의 즐거움을 주지 않습니다. 다른 코스는 단순히 언어 학자를 위한 프로그래밍을 가르치기 위해 고안되었으며 중요한 NLP 컨텐츠를 다루지 않습니다. NLTK는 원래 이 문제를 해결하기 위해 개발 되었기 때문에 학생들이 사전 프로그래밍 경험이 없더라도 단일 학기 과정 내에서 상당한 양의 이론과 실습을 다루는 것이 가능합니다.

NLP 요강의 중요한 부분은 알고리즘과 데이터 구조를 다룹니다. 이런 것을 배우는 것은 지 지루하지만 NLTK는 단계별로 알고리즘을 볼 수있는 대화식 그래픽 사용자 인터페이스의 도움을 받아 재미를 제공합니다. 대부분의 NLTK 구성 요소에는 사용자의 특별한 입력없이 재미있는 작업을 수행하는 데모가 포함되어 있습니다. 자료를 전달하는 효과적인 방법은 이 책의 예제를 대화 형으로 표현하고, Python 세션에 입력하고, 수행 한 내용을 관찰하고, 경험적 또는 이론적 문제를 탐구하기 위해 수정하는 것입니다.

이 책에는 학생 과제물의 기초로 사용할 수있는 수백 가지 연습 문제가 포함되어 있습니다. 가장 간단한 연습은 구체적인 질문에 대답하기 위해 지정된 방법으로 제공된 프로그램 코드를 수정하는 것입니다. NLTK는 모든 기본 데이터 구조 및 알고리즘, 널리 사용되는 수십 개의 데이터 세트 (코퍼라) 인터페이스 및 유연하고 확장 가능한 아키텍처의 표준 구현을 통해 대학원 수준의 연구 프로젝트를위한 유연한 프레임 워크를 제공합니다. NLTK를 사용한 교수법에 대한 추가 지원은 NLTK 웹 사이트에서 가능합니다.

우리는이 책이 학생들이 프로그램을 배우는 맥락에서 NLP에 대해 배울 수있는 포괄적 인 틀을 제공함에있어서 독창적이라고 생각합니다. 장별로 소개하는 자료는 각 장을 다루면서 필요한 내용을 긴밀히 다루기 때문에, 사전 프로그래밍 경험이없는 사람들까지도 NLP에 대한 실질적인 도움을 제공합니다. 이 자료를 마친 후, 학생들은 Jurafsky와 Martin (Prentice Hall, 2008)이 진행하는 말하기와 언어 처리와 같은 고급 교과서 중 하나를 시도 할 배경지식을 갖게 됩니다.

이 책은 프로그래밍 개념을 독특한 순서로 제시하며, 중요한 데이터 유형 (문자열 목록)으로 시작하여 이해 및 조건부와 같은 중요한 제어 구조를 도입합니다. 이러한 접근법은 초심자에게 유용한 언어 처리의 개념을 잡아줍니다. 그후 문자열, 루프, 파일 등과 같은 기본 개념을 체계적으로 보여줍니다. 이런 방식으로, 프로그래밍을 잘 모르는 독자들이라 하더라도 고전적인 방식으로 배우는 배경지식을 동일하게 배우게 해 줍니다.

두 가지 가능한 코스 계획이 IX.1에 설명되어 있습니다. 첫 번째 방식은 예술 / 인문학 관객을 대상으로하고, 두 번째 방식은 과학 / 엔지니어링 관객을 대상으로합니다. 다른 접근 방식은 처음 5 개 챕터를 다루고 남은 챕터를 하나의 큰 주제로 보고 배우는 것입니다. 텍스트 분류 (6-7 장), 구문 (8-9 장), 의미 (10 장) 또는 언어 데이터와 관리 (11장)같은 단일 영역으로 할당 할 수 있습니다.


* 이 책에 사용 된 규칙
이 책에는 다음과 같은 인쇄 규칙이 사용됩니다.

굵게 - 새 용어를 나타냅니다.

기울임 꼴 - 단락 내에서 언어적인 예, 텍스트 이름 및 URL을 나타 내기 위해 사용됩니다. 또한 파일 이름과 파일 확장자에 사용됩니다.

일정한 폭 - 프로그램 목록뿐만 아니라 변수 또는 함수 이름, 명령문 및 키워드와 같은 프로그램 요소를 참조하는 단락 내에서 사용됩니다. 프로그램 이름에도 사용됩니다.

일정한 너비 굵게 - 사용자가 문자 그대로 입력해야하는 명령 또는 기타 텍스트를 표시합니다.

Constant width italic - 사용자 제공 값 또는 컨텍스트에 의해 결정된 값으로 대체되어야하는 텍스트를 표시합니다. 프로그램 코드 예제 내에서 메타 변수에도 사용됩니다.

**감사 인사**

저자는 Doug Arnold, Michaela Atterer, Greg Aumann, Kenneth Beesley, Steven Bethard, Ondrej Bojar, Chris Cieri, Robin Cooper, Grev Corbett, James Curran, Dan Garrette 등이 책의 초안에 대한 피드백을 위해 다음과 같은 사람들에게 빚을졌습니다. Jeni Nelson, Adam Przepiorkowski, Brandon Rhodes, Stuart Robinson, Jussi Salmela, Kyle Schlansker, Rob Speer, Richard Sproat 등이 포함되어 있습니다. 우리는 많은 학생들과 동료들에게 브라질, 인도, 미국의 NLP 및 언어학 여름 학교의 참가자들을 포함하여이 장들로 진화 한 수업 자료에 대한 그들의 의견에 대해 감사를 표합니다. 이 책은 NLTK 웹 사이트에 이름이 지정된 nltk-dev 개발자 커뮤니티의 구성원 없이는 존재하지 않습니다. NLTK 웹 사이트는 NLTK 구축 및 확장에 대한 시간과 전문 지식을 자유롭게 제공했습니다.

이 책에 대한 연구를 지원 한 미국 국립 과학 재단, 언어 데이터 컨소시엄, Edward Clarence Dyason Fellowship, 펜실베니아 대학, 에딘버러 및 멜버른에 감사드립니다.

우리는 Julie Steele, Abby Fox, Loranah Dimant 및 나머지 O'Reilly 팀에게 NLP 및 Python 커뮤니티의 초안에 대한 포괄적 인 리뷰를 구성하고, O'Reilly의 제작 도구를 유쾌하게 사용자 정의하고, 세심한 사본을 작성해 주신 것에 감사드립니다. - 편집 작업.

Python 3 개정판을 준비 할 때 NLTK를 Python 3로 포팅하려는 Michael Korobov와 초판에 대한 그의 세심한 피드백 덕분에 Antoine Trux에게 감사드립니다.

마지막으로, 우리는이 책에서 수년 동안 사랑, 인내, 그리고 지원에 대해 Mimo와 Jee에게 큰 감사를 표합니다. Andrew, Alison, Kirsten, Leonie, Maaike 등의 자녀들이이 페이지에서 언어와 계산에 대한 열정을 가지기를 바랍니다.



**저자 정보**
스티븐 버드 (Steven Bird)는 멜버른 대학교 (University of Melbourne)의 컴퓨터 과학 및 소프트웨어 공학 부교수이자 펜실베니아 대학교의 언어 데이터 컨소시엄 수석 연구원입니다. 그는 Ewan Klein이 감독 한 1990 년 에딘버러 대학 (University of Edinburgh)에서 컴퓨터 음운론에 대한 박사 학위를 취득했습니다. 그는 나중에 Cameroon으로 옮겨 Summer Institute of Linguistics의 후원하에 Grassfields Bantu 언어에 대한 언어 현장 조사를 수행했습니다. 최근에는 Linguistic Data Consortium의 Associate Director로 수년 동안 R & D 팀에서 주석이 달린 대규모 데이터베이스의 모델 및 도구를 만들었습니다. Melbourne University에서는 언어 기술 연구 그룹을 설립하고 학부 컴퓨터 과학 커리큘럼의 모든 수준에서 강의했습니다. 2009 년 Steven은 Computational Linguistics 협회 회장을 지 냈습니다.

Ewan Klein은 University of Edinburgh의 정보 과학 학교의 언어 기술 교수입니다. 그는 1978 년 케임브리지 대학교에서 공식적인 의미론에 대한 박사 학위를 마쳤습니다. 서 섹스 대학과 뉴캐슬 어폰 대학교에서 근무한 지 몇 년 후, 에완은 에딘버러에서 교수직을 맡았습니다. 그는 1993 년 에딘버러 언어 기술 그룹 (Edinburgh 's Language Technology Group)의 설립에 관여했으며, 그 후로도 그와 긴밀하게 연관되어 있습니다. 2000-2002 년에 그는 University에서 Edinburgh에있는 Edible Corporation의 자연어 연구 그룹 (Edinburgh-based Natural Language Research Group)의 연구 책임자로 일하면서 대화 대화 처리를 담당했습니다. Ewan은 전산 언어학 협회의 유럽 지부 총재로 유럽 언어 네트워크 우수 기관 (ELSNET)의 창립 멤버이자 코디네이터입니다.

Edward Loper는 최근 University of Pennsylvania에서 자연어 처리를위한 기계 학습 박사 학위를 취득했습니다. 에드워드는 2000 년 가을 전산 언어학 분야의 스티븐 (Steven) 대학원 과정 학생이었고, TA가되어 NLTK 개발에 참여했습니다. NLTK 외에도 그는 Python 소프트웨어, epydoc 및 doctest를 문서화하고 테스트하기위한 두 개의 패키지를 개발하는 데 도움을주었습니다.

**역자정보**

고현영 - 광운대 전자통신공학과 학부와 대학원을 졸업하였고 현재 킨스미디어( http://www.kinsmedia.com )에서 법률 분석 서비스 및 데이터 시각화 서비스를 만들고 있습니다. 

텍스트 분석을 하는데 국내 자료가 많이 부족함을 봅니다. 오프라인으로 된 자료들은 저같은 초심자가 보기 어렵고 직접 따라해 보기가 쉽지 않았습니다. 외국자료를 보아야 하는데 한국어와는 맞지 않아서 난감하기도 하였습니다. 그래도 KoNLPy나 은전한닢같이 한국어 텍스트처리에 대해 노력하시는 분들이 있기에 많은 도움이 되었습니다. 이 번역도 국어 텍스트 분석자들에게 도움이 되기를 바라며 작업을 시작하게 되었습니다(2018.7.24). 

본 번역은 일차로 구글번역을 통한 기계번역후 검수를 진행하였습니다. 